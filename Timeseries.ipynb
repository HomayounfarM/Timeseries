{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPLZ3FXgmRVZhnIGVwQSF4Z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "ir",
      "display_name": "R"
    },
    "language_info": {
      "name": "R"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HomayounfarM/Timeseries/blob/main/Timeseries.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://colab.research.google.com/#create=true&language=r, or this short URL https://colab.to/r"
      ],
      "metadata": {
        "id": "Jta4S-MVZQUt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Me1_2hnCVeFU"
      },
      "outputs": [],
      "source": [
        "install.packages(\"googledrive\")\n",
        "library(\"googledrive\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Classical Decomposition Model\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "JiT9H9XfZidY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load required libraries\n",
        "library(Kendall)\n",
        "library(tidyverse)\n",
        "library(fpp2) \n",
        "library(forecast) \n",
        "library(tibbletime) \n",
        "library(tsbox) \n",
        "library(gridExtra) \n",
        "library(knitr) \n",
        "library(ggthemes)\n",
        "library(Kendall)"
      ],
      "metadata": {
        "id": "3WHJ31zavNCj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "umVefnuJ2y4p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#install.packages('Kendall')\n",
        "#install.packages('gridExtra')\n",
        "#install.packages('fpp2')\n",
        "#install.packages('tibbletime')\n",
        "#install.packages('tsbox')\n",
        "#install.packages('ggthemes')"
      ],
      "metadata": {
        "id": "l8YWMsTQy3E0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Assuming we have the following time series:"
      ],
      "metadata": {
        "id": "_VNLtH2V5EQk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LakeHuron\n",
        "class(LakeHuron)\n",
        "str(LakeHuron)\n",
        "\n",
        "\n",
        "# Convert time series to tibble object\n",
        "LakeHuron_tbl <- data.frame(water_level=as.numeric(LakeHuron), \n",
        "                        year=as.numeric(time(LakeHuron)))\n",
        "\n",
        "class(LakeHuron_tbl)\n",
        "\n",
        "# Plot the data \n",
        "ggplot(LakeHuron_tbl,aes(x=year,y=water_level)) + \n",
        "  ggtitle(\"Lake Huron water levels (1875-1972)\") + \n",
        "  geom_line() + geom_point() +  \n",
        "  ylab(\"Water Level\") + xlab(\"Year\") "
      ],
      "metadata": {
        "id": "wdHdyO4NV3V7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Perform the Mann-Kendall Trend Test\n",
        "MannKendall(LakeHuron)"
      ],
      "metadata": {
        "id": "cytfPAOP3t18"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The test statistic is -0.354 and the corresponding two-sided p-value is 2.4718e-07. Because this p-value is less than 0.05, we will reject the null hypothesis of the test and conclude that a trend is present in the data."
      ],
      "metadata": {
        "id": "T5-R2M6L4DJc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "So indeed, we have some data from 1875 to 1972 on water levels for Lake Huron. What can we say about the trend? Let’s estimate a couple and see!"
      ],
      "metadata": {
        "id": "TxxhCXax0dIf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "huron_linear <- tslm(LakeHuron ~ trend) ## Fit linear trend \n",
        "huron_quad <- tslm(LakeHuron ~ trend + I(trend^2)) ## Fit quadratic trend \n",
        "huron_ma7 <- ma(LakeHuron, order=7) # Fit a q=3 moving average (ma=2q+1)\n",
        "\n",
        "# Put all of these together\n",
        "LakeHuron_with_fits <- cbind(LakeHuron, \n",
        "                             Linear_trend=fitted(huron_linear), \n",
        "                             Quadratic_trend=fitted(huron_quad),\n",
        "                             Moving_avg7 = huron_ma7) \n",
        "                             \n",
        "# Construct the plot \n",
        "autoplot(LakeHuron_with_fits) + \n",
        "  ylab(\"Water Level (in feet)\") + xlab(\"Year\") +\n",
        "  ggtitle(\"Lake Huron water levels (1875-1972)\") +  \n",
        "  guides(colour= guide_legend(title = \"Data series\")) + \n",
        "  scale_colour_manual(values=c(\"black\",\"red\",\"blue\",\"yellow\"))  "
      ],
      "metadata": {
        "id": "7yu29k8D0cgX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's look at the residuals.\n",
        "Remember that after removing the trend, the result should somehow look like a stationary process or at least like a mean-zero process!"
      ],
      "metadata": {
        "id": "dZz5FGKb5iau"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract residuals for each estimated trend\n",
        "LakeHuron_resids<-cbind(Res_orig=LakeHuron-mean(LakeHuron),\n",
        "                        Res_linear=LakeHuron-fitted(huron_linear),\n",
        "                        Res_quad=LakeHuron-fitted(huron_quad), \n",
        "                        Res_MA7 = LakeHuron - huron_ma7)\n",
        "\n",
        "# produce the autoplot \n",
        "autoplot(LakeHuron_resids, facet=TRUE) + xlab(\"Year\") + ylab(\"Residuals\") +  \n",
        "  ggtitle(\"Lake Huron water levels (1875-1972) Residuals\") + \n",
        "  geom_hline(yintercept = 0) + \n",
        "  guides(colour=guide_legend(title=\"Data Series\"))"
      ],
      "metadata": {
        "id": "Q0SPinch16zx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that for all trends, they definitely look a lot more mean-zero than the original one, and the MA7 (order-7 moving-average) looks a bit more like White Noise than the others. You might also notice that we lost some data along the process: indeed, as we can only go over a window [-q,q], we will lose a couple of observations at the borders. We can inspect this more formally using the ACF plots we had seen before:"
      ],
      "metadata": {
        "id": "gaTfi87A565V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ggAcf(LakeHuron) + ggtitle(\"ACF for original series\") + ylim(c(-1,1))\n",
        "ggAcf(LakeHuron_resids[,\"Res_linear\"]) + ggtitle(\"ACF removing linear trend\") + ylim(c(-1,1)) \n",
        "ggAcf(LakeHuron_resids[,\"Res_quad\"]) + ggtitle(\"ACF removing quadratic trend\") + ylim(c(-1,1)) \n",
        "ggAcf(LakeHuron_resids[,\"Res_MA7\"]) + ggtitle(\"ACF removing MA7 trend\")+ ylim(c(-1,1))"
      ],
      "metadata": {
        "id": "naiuQIkl29v6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Indeed, all of our trend estimations do significantly much better than the original series, as more lags fall within the confidence bounds. However, we see that sometimes over-estimating the trend can lead to further correlation. Overall, the MA7 seems to be the best choice. The drawback is that by employing an MA filter, we sacrifice some data, and therefore, some predictive power. In the end, it is up to you to make these choices over which trend estimation to use over another!"
      ],
      "metadata": {
        "id": "YBwmFJlW6Bb-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://medium.com/analytics-vidhya/a-complete-introduction-to-time-series-analysis-with-r-classical-decomposition-model-a4548a0c99b9"
      ],
      "metadata": {
        "id": "uKMUL5j64EeS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ARIMA\n",
        "ARIMA is an acronym for Auto Regressive (AR) Integrated (I) Moving Average (MA) which indicates that an ARIMA model has three components to it.\n",
        "\n",
        "ARIMA models can be expressed in two forms: Non-seasonal models where the model exhibits an order in the form of (p,d,q) where:\n",
        "\n",
        "p = The order of the Auto Regressive Model\n",
        "\n",
        "d = The order of differencing\n",
        "\n",
        "q = The order of the Moving Average\n",
        "\n",
        "###Auto Regressive Models (AR):\n",
        "\n",
        "Auto regressive models are similar to a regression model but the regressor in this case is the same dependent variable with a specific lag.\n",
        "\n",
        "###Differencing (I):\n",
        "\n",
        "For ARIMA to perform at its best it needs the data to be stationary. That means that the mean and variance are constant over the entire set. Differencing is used to transform the data so that it is stationary.\n",
        "\n",
        "###Moving Average (MA):\n",
        "\n",
        "Moving averages are widely used in time series analysis and is an already well-known concept. It involves getting the average of the points in a series for a specific lag.\n",
        "\n",
        "###Seasonal ARIMA models (SARIMA):\n",
        "\n",
        "These models take into account the seasonality in the data and does the same ARIMA steps but on the seasonal pattern. So, if the data has a seasonal pattern every quarter then the SARIMA will get an order for (p,d,q) for all the points and a (P,D,Q) for each quarter.\n",
        "\n",
        "###Regression Models VS. ARIMA:\n",
        "\n",
        "Now comes the real deal. ARIMA models are great for forecasting blindly into the future using historical data. However, sometimes we don’t need to forecast blindly, sometimes we have variables that can help us predict future behavior. Regression models are ideal in this scenario."
      ],
      "metadata": {
        "id": "2R3dnT1OvJAM"
      }
    }
  ]
}